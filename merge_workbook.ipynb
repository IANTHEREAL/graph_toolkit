{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>entity_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_description</th>\n",
       "      <th>entity_metadata</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iFWJsx6B_iter_1_idx1</td>\n",
       "      <td>362741</td>\n",
       "      <td>Region</td>\n",
       "      <td>A Region is a basic unit of data storage and d...</td>\n",
       "      <td>{'details': {'function': 'Data partition in Ti...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iFWJsx6B_iter_1_idx1</td>\n",
       "      <td>390267</td>\n",
       "      <td>Region</td>\n",
       "      <td>In TiKV, a Region is a contiguous segment of t...</td>\n",
       "      <td>{'context': 'TiKV', 'definition': 'a segment o...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iFWJsx6B_iter_1_idx2</td>\n",
       "      <td>56028</td>\n",
       "      <td>Region</td>\n",
       "      <td>A Region is the basic unit of data storage and...</td>\n",
       "      <td>{'details': ['Replicated across multiple TiKV ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iFWJsx6B_iter_1_idx2</td>\n",
       "      <td>362741</td>\n",
       "      <td>Region</td>\n",
       "      <td>A Region is a basic unit of data storage and d...</td>\n",
       "      <td>{'details': {'function': 'Data partition in Ti...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iFWJsx6B_iter_1_idx3</td>\n",
       "      <td>390220</td>\n",
       "      <td>Region</td>\n",
       "      <td>A basic data storage unit in TiKV. Backups are...</td>\n",
       "      <td>{'backup_process': ['Backed up by TiKV', 'Back...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Gt4UtkMP_iter_1_idx1</td>\n",
       "      <td>58482</td>\n",
       "      <td>Table</td>\n",
       "      <td>Derived from from relationship: Table -&gt; Table...</td>\n",
       "      <td>{'status': 'need-revised'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>gNTT5hHo_iter_1_idx1</td>\n",
       "      <td>363070</td>\n",
       "      <td>MySQL</td>\n",
       "      <td>Derived from relationships: MySQL provides sta...</td>\n",
       "      <td>{'status': 'need-revised'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>gNTT5hHo_iter_1_idx1</td>\n",
       "      <td>47420</td>\n",
       "      <td>MySQL</td>\n",
       "      <td>Derived from from relationship: SHOW STATUS st...</td>\n",
       "      <td>{'status': 'need-revised'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>gNTT5hHo_iter_1_idx1</td>\n",
       "      <td>47678</td>\n",
       "      <td>MySQL</td>\n",
       "      <td>Derived from from relationship: SHOW BINDINGS ...</td>\n",
       "      <td>{'status': 'need-revised'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>gNTT5hHo_iter_1_idx1</td>\n",
       "      <td>48646</td>\n",
       "      <td>MySQL</td>\n",
       "      <td>Derived from from relationship: SHOW ENGINES s...</td>\n",
       "      <td>{'status': 'need-revised'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  cluster  entity_id entity_name  \\\n",
       "0    iFWJsx6B_iter_1_idx1     362741      Region   \n",
       "1    iFWJsx6B_iter_1_idx1     390267      Region   \n",
       "2    iFWJsx6B_iter_1_idx2      56028      Region   \n",
       "3    iFWJsx6B_iter_1_idx2     362741      Region   \n",
       "4    iFWJsx6B_iter_1_idx3     390220      Region   \n",
       "..                    ...        ...         ...   \n",
       "137  Gt4UtkMP_iter_1_idx1      58482       Table   \n",
       "138  gNTT5hHo_iter_1_idx1     363070       MySQL   \n",
       "139  gNTT5hHo_iter_1_idx1      47420       MySQL   \n",
       "140  gNTT5hHo_iter_1_idx1      47678       MySQL   \n",
       "141  gNTT5hHo_iter_1_idx1      48646       MySQL   \n",
       "\n",
       "                                    entity_description  \\\n",
       "0    A Region is a basic unit of data storage and d...   \n",
       "1    In TiKV, a Region is a contiguous segment of t...   \n",
       "2    A Region is the basic unit of data storage and...   \n",
       "3    A Region is a basic unit of data storage and d...   \n",
       "4    A basic data storage unit in TiKV. Backups are...   \n",
       "..                                                 ...   \n",
       "137  Derived from from relationship: Table -> Table...   \n",
       "138  Derived from relationships: MySQL provides sta...   \n",
       "139  Derived from from relationship: SHOW STATUS st...   \n",
       "140  Derived from from relationship: SHOW BINDINGS ...   \n",
       "141  Derived from from relationship: SHOW ENGINES s...   \n",
       "\n",
       "                                       entity_metadata  processed  \n",
       "0    {'details': {'function': 'Data partition in Ti...      False  \n",
       "1    {'context': 'TiKV', 'definition': 'a segment o...      False  \n",
       "2    {'details': ['Replicated across multiple TiKV ...      False  \n",
       "3    {'details': {'function': 'Data partition in Ti...      False  \n",
       "4    {'backup_process': ['Backed up by TiKV', 'Back...      False  \n",
       "..                                                 ...        ...  \n",
       "137                         {'status': 'need-revised'}      False  \n",
       "138                         {'status': 'need-revised'}      False  \n",
       "139                         {'status': 'need-revised'}      False  \n",
       "140                         {'status': 'need-revised'}      False  \n",
       "141                         {'status': 'need-revised'}      False  \n",
       "\n",
       "[142 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from llm_inference.base import LLMInterface\n",
    "from setting.db import SessionLocal\n",
    "import logging\n",
    "from models.entity import get_entity_model\n",
    "from models.relationship import get_relationship_model\n",
    "\n",
    "\n",
    "Entity = get_entity_model(\"entities_150001\", 1536)\n",
    "Relationship = get_relationship_model(\"relationships_150001\", 1536)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "llm_client = LLMInterface(\"ollama\", \"deepseek-qwen-32b\")\n",
    "cluster_df = pd.read_pickle(\"cluster_entities.pkl\")\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "\n",
    "from typing import Mapping, Any\n",
    "\n",
    "embedding_model = openai.OpenAI()\n",
    "\n",
    "def get_text_embedding(text: str, model=\"text-embedding-3-small\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return embedding_model.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "\n",
    "def get_entity_description_embedding(\n",
    "    name: str, description: str\n",
    "):\n",
    "    combined_text = f\"{name}: {description}\"\n",
    "    return get_text_embedding(combined_text)\n",
    "\n",
    "\n",
    "def get_entity_metadata_embedding(\n",
    "    metadata: dict[Mapping, Any]\n",
    "):\n",
    "    combined_text = json.dumps(metadata)\n",
    "    return get_text_embedding(combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: iFWJsx6B_iter_1_idx1\n",
      " - ID: 390267, Name: Region, Description: In TiKV, a Region is a contiguous segment of the key-value space, represented by a left-closed and right-open interval [StartKey, EndKey). It serves as the basic unit for data distribution and Raft replication. A Region consists of a series of adjacent keys and is replicated using the Raft algorithm to form a Raft Group.\n",
      "   - Metadata: {'context': 'TiKV', 'definition': 'a segment of the key-value space, consisting of a series of adjacent keys', 'details': ['Consecutive segment of Key-Value pairs.', 'Represented by [StartKey, EndKey).', 'Default size limit is 96 MiB (configurable)', 'Basic unit for data distribution and Raft replication.'], 'further_information': 'TiDB Internal (I) - Data Storage (https://www.pingcap.com/blog/tidb-internal-data-storage/)', 'location': 'TiKV', 'note': 'Incorrect key counting in some cases', 'properties': ['basic unit of data distribution in TiKV', 'represents a range of keys', 'replicated using Raft algorithm', 'multiple replicas form a Raft Group'], 'topic': ['Characteristics', 'Key Range', 'Region']}\n",
      " - ID: 362741, Name: Region, Description: A Region is a basic unit of data storage and distribution in the TiDB ecosystem, specifically within TiKV. It is managed by the Placement Driver (PD) and the Raft consensus algorithm. Regions are crucial for data partitioning and distribution, and they can become unavailable due to various issues. They are involved in data replication processes, such as applying Region snapshots and ingesting SST files. During restore operations, metadata is read from each TiKV, and a leader is selected for each Region using a leader selection algorithm.\n",
      "   - Metadata: {'details': {'function': 'Data partition in TiKV.', 'issues': 'Can become unavailable due to various issues.'}, 'features': ['Add more metrics for Region and store heartbeat', 'Add Grafana panels for data replication (`apply Region snapshots` and `ingest SST files`)'], 'issues_fixed': ['Region stuck in multi-time merging', 'Exception when resolving locks for Regions', 'Check for Region meta for correct Region Split/Region Merge'], 'properties': [{'property': 'Metadata', 'value': 'Read by BR from each TiKV during restore'}, {'property': 'Leader Selection', 'value': 'BR selects the leader of each Region with a leader selection algorithm'}], 'status': 'need-revised', 'subtopic': ['Distribution fetched from PD by BR'], 'topic': ['Region', 'storage', 'Bug Fixes', 'Data Partitioning', 'Data Distribution Unit']}\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "from entity_agg import merge_entities, should_merge_entities, group_mergeable_entities\n",
    "\n",
    "cluster_mapping = {}\n",
    "for _, row in cluster_df.iterrows():\n",
    "    if row['processed'] == True:\n",
    "        continue\n",
    "\n",
    "    cluster_name = row['cluster']\n",
    "    entity = Entity(\n",
    "        id=row['entity_id'],\n",
    "        name=row['entity_name'],\n",
    "        description=row['entity_description'],\n",
    "        meta=row['entity_metadata']\n",
    "    )\n",
    "    \n",
    "    if cluster_name not in cluster_mapping:\n",
    "        cluster_mapping[cluster_name] = set()\n",
    "    \n",
    "    cluster_mapping[cluster_name].add(entity)\n",
    "\n",
    "if cluster_mapping:\n",
    "    first_cluster = next(iter(cluster_mapping))\n",
    "    print(f\"Cluster: {first_cluster}\")\n",
    "    for entity in cluster_mapping[first_cluster]:\n",
    "        print(f\" - ID: {entity.id}, Name: {entity.name}, Description: {entity.description}\")\n",
    "        print(f\"   - Metadata: {entity.meta}\")\n",
    "\n",
    "print(len(cluster_mapping))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge entities cluster iFWJsx6B_iter_1_idx1, count 2\n",
      "prompt token 1141\n",
      "Region\n",
      "Merged entity created with ID: 540060\n",
      "Relationships updated for merged entity 540060\n",
      "Merged entity iFWJsx6B_iter_1_idx1 processing complete.\n",
      "****************************************************************************************************\n",
      "merge entities cluster iFWJsx6B_iter_1_idx2, count 2\n",
      "prompt token 1007\n",
      "Region\n",
      "Merged entity created with ID: 540061\n",
      "Relationships updated for merged entity 540061\n",
      "Merged entity iFWJsx6B_iter_1_idx2 processing complete.\n",
      "****************************************************************************************************\n",
      "merge entities cluster iFWJsx6B_iter_1_idx3, count 2\n",
      "prompt token 1059\n",
      "Region\n",
      "Merged entity created with ID: 540062\n",
      "Relationships updated for merged entity 540062\n",
      "Merged entity iFWJsx6B_iter_1_idx3 processing complete.\n",
      "****************************************************************************************************\n",
      "merge entities cluster grbSNNAY_iter_1_idx1, count 2\n",
      "prompt token 616\n",
      "TiKV\n",
      "Merged entity created with ID: 540063\n",
      "Relationships updated for merged entity 540063\n",
      "Merged entity grbSNNAY_iter_1_idx1 processing complete.\n",
      "****************************************************************************************************\n",
      "merge entities cluster grbSNNAY_iter_1_idx2, count 2\n",
      "prompt token 988\n",
      "TiKV\n",
      "Merged entity created with ID: 540064\n",
      "Relationships updated for merged entity 540064\n",
      "Merged entity grbSNNAY_iter_1_idx2 processing complete.\n",
      "****************************************************************************************************\n",
      "merge entities cluster L0HiZHjN_iter_1_idx1, count 3\n",
      "prompt token 875\n",
      "Table\n",
      "Merged entity created with ID: 540065\n",
      "Relationships updated for merged entity 540065\n",
      "Merged entity L0HiZHjN_iter_1_idx1 processing complete.\n",
      "****************************************************************************************************\n",
      "merge entities cluster L0HiZHjN_iter_1_idx2, count 7\n",
      "prompt token 1343\n",
      "Table\n",
      "Merged entity created with ID: 540066\n",
      "Relationships updated for merged entity 540066\n",
      "Merged entity L0HiZHjN_iter_1_idx2 processing complete.\n",
      "****************************************************************************************************\n",
      "merge entities cluster L0HiZHjN_iter_1_idx3, count 4\n",
      "prompt token 834\n",
      "Table\n",
      "Merged entity created with ID: 540067\n",
      "Relationships updated for merged entity 540067\n",
      "Merged entity L0HiZHjN_iter_1_idx3 processing complete.\n",
      "****************************************************************************************************\n",
      "merge entities cluster N8ssyFDY_iter_1_idx1, count 3\n",
      "prompt token 2322\n",
      "TiCDC\n",
      "Merged entity created with ID: 540068\n",
      "Relationships updated for merged entity 540068\n",
      "Merged entity N8ssyFDY_iter_1_idx1 processing complete.\n",
      "****************************************************************************************************\n",
      "merge entities cluster N8ssyFDY_iter_1_idx2, count 2\n",
      "prompt token 632\n",
      "TiCDC\n",
      "Merged entity created with ID: 540069\n",
      "Relationships updated for merged entity 540069\n",
      "Merged entity N8ssyFDY_iter_1_idx2 processing complete.\n",
      "****************************************************************************************************\n",
      "merge entities cluster qlUlRh9g_iter_1_idx1, count 8\n",
      "prompt token 2090\n",
      "TiDB\n",
      "Merged entity created with ID: 540070\n",
      "Relationships updated for merged entity 540070\n",
      "Merged entity qlUlRh9g_iter_1_idx1 processing complete.\n",
      "****************************************************************************************************\n",
      "merge entities cluster OxDK2dk9_iter_1_idx1, count 2\n",
      "prompt token 1140\n",
      "PD\n",
      "Merged entity created with ID: 540071\n",
      "Relationships updated for merged entity 540071\n",
      "Merged entity OxDK2dk9_iter_1_idx1 processing complete.\n",
      "****************************************************************************************************\n",
      "merge entities cluster OxDK2dk9_iter_1_idx2, count 2\n",
      "prompt token 599\n",
      "PD\n",
      "Merged entity created with ID: 540072\n",
      "Relationships updated for merged entity 540072\n",
      "Merged entity OxDK2dk9_iter_1_idx2 processing complete.\n",
      "****************************************************************************************************\n",
      "merge entities cluster OxDK2dk9_iter_1_idx3, count 2\n",
      "prompt token 599\n",
      "PD\n",
      "Merged entity created with ID: 540073\n",
      "Relationships updated for merged entity 540073\n",
      "Merged entity OxDK2dk9_iter_1_idx3 processing complete.\n",
      "****************************************************************************************************\n",
      "merge entities cluster PpqeOrGJ_iter_1_idx1, count 32\n",
      "prompt token 5934\n"
     ]
    }
   ],
   "source": [
    "for cluster_name, entities in cluster_mapping.items():\n",
    "    print(f\"merge entities cluster {cluster_name}, count {len(entities)}\")\n",
    "\n",
    "    token_count = merge_entities(llm_client, entities, only_count_token=True)\n",
    "    if token_count > 16384:\n",
    "        print(\"prompt token exceeds 16384\", token_count)\n",
    "        continue\n",
    "\n",
    "    model_args = {}\n",
    "    if token_count > 7000:\n",
    "        model_args[\"options\"]={\n",
    "            \"num_ctx\": token_count+1500,\n",
    "            \"num_gpu\": 80,\n",
    "            \"num_predict\": 8192,\n",
    "            \"temperature\": 0.1,\n",
    "        }\n",
    "    else:\n",
    "        model_args[\"options\"]={\n",
    "            \"num_ctx\": 8092,\n",
    "            \"num_gpu\": 80,\n",
    "            \"num_predict\": 8192,\n",
    "            \"temperature\": 0.1,\n",
    "        }\n",
    "\n",
    "    print(\"prompt token\", token_count)\n",
    "    try:\n",
    "        be_continued =  should_merge_entities(llm_client, entities, **model_args)\n",
    "        if be_continued is False:\n",
    "            print(f\"skip merge entities cluster {cluster_name}, count {len(entities)}\")\n",
    "            continue\n",
    "        merged_entity = merge_entities(llm_client, entities, **model_args)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing cluster {cluster_name}: {e}\", exc_info=True)\n",
    "        continue\n",
    "\n",
    "    if isinstance(merged_entity,dict) and \"name\" in merged_entity and \"description\" in merged_entity and \"meta\" in merged_entity:\n",
    "        try:\n",
    "            with SessionLocal() as session:\n",
    "                # Step 1: Write the merged entity to the database\n",
    "                new_entity = Entity(\n",
    "                    name=merged_entity[\"name\"],\n",
    "                    description=merged_entity[\"description\"],\n",
    "                    meta=merged_entity.get(\"meta\", {}),\n",
    "                    description_vec=get_entity_description_embedding(merged_entity[\"name\"], merged_entity[\"description\"]),\n",
    "                    meta_vec=get_entity_metadata_embedding(merged_entity.get(\"meta\", {}))\n",
    "                )\n",
    "                print(new_entity.name)\n",
    "                session.add(new_entity)\n",
    "                session.flush()\n",
    "                merged_entity_id = new_entity.id\n",
    "                print(f\"Merged entity created with ID: {merged_entity_id}\")\n",
    "                original_entity_ids = {entity.id for entity in entities}\n",
    "                 # Step 2: Update relationships to reference the merged entity\n",
    "                # Bulk update source entity IDs\n",
    "                session.execute(\n",
    "                    Relationship.__table__.update().where(\n",
    "                        Relationship.source_entity_id.in_(original_entity_ids)\n",
    "                    ).values(source_entity_id=merged_entity_id)\n",
    "                )\n",
    "\n",
    "                # Bulk update target entity IDs\n",
    "                session.execute(\n",
    "                    Relationship.__table__.update().where(\n",
    "                        Relationship.target_entity_id.in_(original_entity_ids)\n",
    "                    ).values(target_entity_id=merged_entity_id)\n",
    "                )\n",
    "\n",
    "                print(f\"Relationships updated for merged entity {merged_entity_id}\")\n",
    "\n",
    "                session.commit()  # Commit the relationship updates\n",
    "                print(f\"Merged entity {cluster_name} processing complete.\")\n",
    "                cluster_df.loc[cluster_df[\"cluster\"] == cluster_name, \"processed\"] = True\n",
    "                cluster_df.to_pickle(\"cluster_entities.pkl\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing cluster {cluster_name}: {e}\", exc_info=True)\n",
    "\n",
    "            print(f\"Error processing cluster {cluster_name}: {e}\")\n",
    "            session.rollback()\n",
    "        finally:\n",
    "            session.close()\n",
    "    else:\n",
    "        print(f\"Merged entity {cluster_name} is invalid or empty.\", merged_entity)\n",
    "\n",
    "    print(\"*\"* 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "SELECT e.id, e.name\n",
    "FROM entities_150001 e\n",
    "WHERE NOT EXISTS (\n",
    "  SELECT 1\n",
    "  FROM relationships_150001 r\n",
    "  WHERE r.source_entity_id = e.id\n",
    "     OR r.target_entity_id = e.id\n",
    ");\n",
    "```\n",
    "\n",
    "```sql\n",
    "START TRANSACTION;\n",
    "\n",
    "DELETE FROM entities_150001\n",
    "WHERE NOT EXISTS (\n",
    "  SELECT 1\n",
    "  FROM relationships_150001 r\n",
    "  WHERE r.source_entity_id = entities_150001.id\n",
    "     OR r.target_entity_id = entities_150001.id\n",
    ");\n",
    "\n",
    "SELECT ROW_COUNT();\n",
    "\n",
    "COMMIT;\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
