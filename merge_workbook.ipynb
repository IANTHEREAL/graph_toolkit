{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>entity_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_description</th>\n",
       "      <th>entity_metadata</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YbnSTRiH_iter_1_idx1_idx1</td>\n",
       "      <td>720296</td>\n",
       "      <td>TiKV</td>\n",
       "      <td>Derived from relationships: Pump queries TiKV ...</td>\n",
       "      <td>{'status': 'need-merged'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YbnSTRiH_iter_1_idx1_idx1</td>\n",
       "      <td>363280</td>\n",
       "      <td>tikv</td>\n",
       "      <td>The TiKV storage engine is a key-value compone...</td>\n",
       "      <td>{'package': 'TiDB-community-server', 'role': '...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YbnSTRiH_iter_1_idx1_idx2</td>\n",
       "      <td>810020</td>\n",
       "      <td>TiKV</td>\n",
       "      <td>TiKV is a distributed key-value store designed...</td>\n",
       "      <td>{'status': 'need-revised'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YbnSTRiH_iter_1_idx1_idx2</td>\n",
       "      <td>720274</td>\n",
       "      <td>TiKV</td>\n",
       "      <td>TiKV is a distributed key-value storage engine...</td>\n",
       "      <td>{'Key Metrics': {'CPU': 'The CPU usage ratio o...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YbnSTRiH_iter_1_idx2_idx1</td>\n",
       "      <td>36322</td>\n",
       "      <td>TiKV</td>\n",
       "      <td>Derived from from relationship: TiKV -&gt; TiKV c...</td>\n",
       "      <td>{'status': 'need-revised'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>YbnSTRiH_iter_1_idx2_idx1</td>\n",
       "      <td>34246</td>\n",
       "      <td>TiKV</td>\n",
       "      <td>Derived from from relationship: TiKV -&gt; TiKV i...</td>\n",
       "      <td>{'status': 'need-revised'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>YbnSTRiH_iter_1_idx2_idx1</td>\n",
       "      <td>61260</td>\n",
       "      <td>TiKV</td>\n",
       "      <td>Derived from from relationship: tidb_session_a...</td>\n",
       "      <td>{'status': 'need-revised'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>YbnSTRiH_iter_1_idx2_idx1</td>\n",
       "      <td>92782</td>\n",
       "      <td>TiKV</td>\n",
       "      <td>Derived from from relationship: enableDynamicC...</td>\n",
       "      <td>{'status': 'need-revised'}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>YbnSTRiH_iter_1_idx2_idx2</td>\n",
       "      <td>242242</td>\n",
       "      <td>TiKV</td>\n",
       "      <td>A component of TiDB Operator that should not b...</td>\n",
       "      <td>{'scaling_restriction': 'Should not be scaled ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>YbnSTRiH_iter_1_idx2_idx2</td>\n",
       "      <td>240738</td>\n",
       "      <td>TiKV</td>\n",
       "      <td>TiKV in TiDB 3.0.1 includes added statistics o...</td>\n",
       "      <td>{'bug_fixes': ['Fix core dump issues'], 'featu...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>YbnSTRiH_iter_1_idx2_idx2</td>\n",
       "      <td>270436</td>\n",
       "      <td>TiKV</td>\n",
       "      <td>The TiKV component in TiDB 2.1 RC5 improves er...</td>\n",
       "      <td>{'additions': [{'feature': 'panic mark file', ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>YbnSTRiH_iter_1_idx2_idx2</td>\n",
       "      <td>43694</td>\n",
       "      <td>TiKV</td>\n",
       "      <td>TiKV in TiDB 3.1 Beta supports distributed bac...</td>\n",
       "      <td>{'features': [{'pull_request': '5532', 'topic'...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      cluster  entity_id entity_name  \\\n",
       "0   YbnSTRiH_iter_1_idx1_idx1     720296        TiKV   \n",
       "1   YbnSTRiH_iter_1_idx1_idx1     363280        tikv   \n",
       "2   YbnSTRiH_iter_1_idx1_idx2     810020        TiKV   \n",
       "3   YbnSTRiH_iter_1_idx1_idx2     720274        TiKV   \n",
       "4   YbnSTRiH_iter_1_idx2_idx1      36322        TiKV   \n",
       "5   YbnSTRiH_iter_1_idx2_idx1      34246        TiKV   \n",
       "6   YbnSTRiH_iter_1_idx2_idx1      61260        TiKV   \n",
       "7   YbnSTRiH_iter_1_idx2_idx1      92782        TiKV   \n",
       "8   YbnSTRiH_iter_1_idx2_idx2     242242        TiKV   \n",
       "9   YbnSTRiH_iter_1_idx2_idx2     240738        TiKV   \n",
       "10  YbnSTRiH_iter_1_idx2_idx2     270436        TiKV   \n",
       "11  YbnSTRiH_iter_1_idx2_idx2      43694        TiKV   \n",
       "\n",
       "                                   entity_description  \\\n",
       "0   Derived from relationships: Pump queries TiKV ...   \n",
       "1   The TiKV storage engine is a key-value compone...   \n",
       "2   TiKV is a distributed key-value store designed...   \n",
       "3   TiKV is a distributed key-value storage engine...   \n",
       "4   Derived from from relationship: TiKV -> TiKV c...   \n",
       "5   Derived from from relationship: TiKV -> TiKV i...   \n",
       "6   Derived from from relationship: tidb_session_a...   \n",
       "7   Derived from from relationship: enableDynamicC...   \n",
       "8   A component of TiDB Operator that should not b...   \n",
       "9   TiKV in TiDB 3.0.1 includes added statistics o...   \n",
       "10  The TiKV component in TiDB 2.1 RC5 improves er...   \n",
       "11  TiKV in TiDB 3.1 Beta supports distributed bac...   \n",
       "\n",
       "                                      entity_metadata  processed  \n",
       "0                           {'status': 'need-merged'}      False  \n",
       "1   {'package': 'TiDB-community-server', 'role': '...      False  \n",
       "2                          {'status': 'need-revised'}      False  \n",
       "3   {'Key Metrics': {'CPU': 'The CPU usage ratio o...      False  \n",
       "4                          {'status': 'need-revised'}      False  \n",
       "5                          {'status': 'need-revised'}      False  \n",
       "6                          {'status': 'need-revised'}      False  \n",
       "7                          {'status': 'need-revised'}      False  \n",
       "8   {'scaling_restriction': 'Should not be scaled ...      False  \n",
       "9   {'bug_fixes': ['Fix core dump issues'], 'featu...      False  \n",
       "10  {'additions': [{'feature': 'panic mark file', ...      False  \n",
       "11  {'features': [{'pull_request': '5532', 'topic'...      False  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from llm_inference.base import LLMInterface\n",
    "from setting.db import SessionLocal\n",
    "import logging\n",
    "from models.entity import get_entity_model\n",
    "from models.relationship import get_relationship_model\n",
    "\n",
    "\n",
    "Entity = get_entity_model(\"entities_150001\", 1536)\n",
    "Relationship = get_relationship_model(\"relationships_150001\", 1536)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "llm_client = LLMInterface(\"ollama\", \"deepseek-qwen-32b\")\n",
    "cluster_df = pd.read_pickle(\"cluster_entities.pkl\")\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "\n",
    "from typing import Mapping, Any\n",
    "\n",
    "embedding_model = openai.OpenAI()\n",
    "\n",
    "def get_text_embedding(text: str, model=\"text-embedding-3-small\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return embedding_model.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "\n",
    "def get_entity_description_embedding(\n",
    "    name: str, description: str\n",
    "):\n",
    "    combined_text = f\"{name}: {description}\"\n",
    "    return get_text_embedding(combined_text)\n",
    "\n",
    "\n",
    "def get_entity_metadata_embedding(\n",
    "    metadata: dict[Mapping, Any]\n",
    "):\n",
    "    combined_text = json.dumps(metadata)\n",
    "    return get_text_embedding(combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: YbnSTRiH_iter_1_idx1_idx1\n",
      " - ID: 720296, Name: TiKV, Description: Derived from relationships: Pump queries TiKV for transaction status, and the `TIKV_STORE_STATUS` table provides information about TiKV nodes.\n",
      "   - Metadata: {'status': 'need-merged'}\n",
      " - ID: 363280, Name: tikv, Description: The TiKV storage engine is a key-value component within the TiDB cluster, serving as the storage engine used by TiDB.\n",
      "   - Metadata: {'package': 'TiDB-community-server', 'role': 'key-value storage', 'topic': ['Storage Engine', 'tikv']}\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "from entity_agg import merge_entities, should_merge_entities, group_mergeable_entities\n",
    "\n",
    "cluster_mapping = {}\n",
    "for _, row in cluster_df.iterrows():\n",
    "    if row['processed'] == True:\n",
    "        continue\n",
    "\n",
    "    cluster_name = row['cluster']\n",
    "    entity = Entity(\n",
    "        id=row['entity_id'],\n",
    "        name=row['entity_name'],\n",
    "        description=row['entity_description'],\n",
    "        meta=row['entity_metadata']\n",
    "    )\n",
    "    \n",
    "    if cluster_name not in cluster_mapping:\n",
    "        cluster_mapping[cluster_name] = set()\n",
    "    \n",
    "    cluster_mapping[cluster_name].add(entity)\n",
    "\n",
    "if cluster_mapping:\n",
    "    first_cluster = next(iter(cluster_mapping))\n",
    "    print(f\"Cluster: {first_cluster}\")\n",
    "    for entity in cluster_mapping[first_cluster]:\n",
    "        print(f\" - ID: {entity.id}, Name: {entity.name}, Description: {entity.description}\")\n",
    "        print(f\"   - Metadata: {entity.meta}\")\n",
    "\n",
    "print(len(cluster_mapping))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge entities cluster YbnSTRiH_iter_1_idx1_idx1, count 2\n",
      "prompt token 526\n",
      "TiKV\n",
      "Merged entity created with ID: 810021\n",
      "Relationships updated for merged entity 810021\n",
      "Merged entity YbnSTRiH_iter_1_idx1_idx1 processing complete.\n",
      "****************************************************************************************************\n",
      "merge entities cluster YbnSTRiH_iter_1_idx1_idx2, count 2\n",
      "prompt token 3893\n",
      "TiKV\n",
      "Merged entity created with ID: 810022\n",
      "Relationships updated for merged entity 810022\n",
      "Merged entity YbnSTRiH_iter_1_idx1_idx2 processing complete.\n",
      "****************************************************************************************************\n",
      "merge entities cluster YbnSTRiH_iter_1_idx2_idx1, count 4\n",
      "prompt token 626\n",
      "TiKV\n",
      "Merged entity created with ID: 810023\n",
      "Relationships updated for merged entity 810023\n",
      "Merged entity YbnSTRiH_iter_1_idx2_idx1 processing complete.\n",
      "****************************************************************************************************\n",
      "merge entities cluster YbnSTRiH_iter_1_idx2_idx2, count 4\n",
      "prompt token 840\n",
      "TiKV\n",
      "Merged entity created with ID: 810024\n",
      "Relationships updated for merged entity 810024\n",
      "Merged entity YbnSTRiH_iter_1_idx2_idx2 processing complete.\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for cluster_name, entities in cluster_mapping.items():\n",
    "    print(f\"merge entities cluster {cluster_name}, count {len(entities)}\")\n",
    "\n",
    "    token_count = merge_entities(llm_client, entities, only_count_token=True)\n",
    "    if token_count > 16384:\n",
    "        print(\"prompt token exceeds 16384\", token_count)\n",
    "        continue\n",
    "\n",
    "    model_args = {}\n",
    "    if token_count > 7000:\n",
    "        model_args[\"options\"]={\n",
    "            \"num_ctx\": token_count+1500,\n",
    "            \"num_gpu\": 80,\n",
    "            \"num_predict\": 10000,\n",
    "            \"temperature\": 0.1,\n",
    "        }\n",
    "    else:\n",
    "        model_args[\"options\"]={\n",
    "            \"num_ctx\": 8092,\n",
    "            \"num_gpu\": 80,\n",
    "            \"num_predict\": 10000,\n",
    "            \"temperature\": 0.1,\n",
    "        }\n",
    "\n",
    "    print(\"prompt token\", token_count)\n",
    "    try:\n",
    "        check_result =  should_merge_entities(llm_client, entities, **model_args)\n",
    "        if check_result.get(\"should_merge\", False) is False:\n",
    "            print(f\"skip merge entities cluster {cluster_name}, count {len(entities)}, reason {check_result}\")\n",
    "            continue\n",
    "        merged_entity = merge_entities(llm_client, entities, **model_args)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing cluster {cluster_name}: {e}\", exc_info=True)\n",
    "        continue\n",
    "\n",
    "    if isinstance(merged_entity,dict) and \"name\" in merged_entity and \"description\" in merged_entity and \"meta\" in merged_entity:\n",
    "        try:\n",
    "            with SessionLocal() as session:\n",
    "                # Step 1: Write the merged entity to the database\n",
    "                new_entity = Entity(\n",
    "                    name=merged_entity[\"name\"],\n",
    "                    description=merged_entity[\"description\"],\n",
    "                    meta=merged_entity.get(\"meta\", {}),\n",
    "                    description_vec=get_entity_description_embedding(merged_entity[\"name\"], merged_entity[\"description\"]),\n",
    "                    meta_vec=get_entity_metadata_embedding(merged_entity.get(\"meta\", {}))\n",
    "                )\n",
    "                print(new_entity.name)\n",
    "                session.add(new_entity)\n",
    "                session.flush()\n",
    "                merged_entity_id = new_entity.id\n",
    "                print(f\"Merged entity created with ID: {merged_entity_id}\")\n",
    "                original_entity_ids = {entity.id for entity in entities}\n",
    "                 # Step 2: Update relationships to reference the merged entity\n",
    "                # Bulk update source entity IDs\n",
    "                session.execute(\n",
    "                    Relationship.__table__.update().where(\n",
    "                        Relationship.source_entity_id.in_(original_entity_ids)\n",
    "                    ).values(source_entity_id=merged_entity_id)\n",
    "                )\n",
    "\n",
    "                # Bulk update target entity IDs\n",
    "                session.execute(\n",
    "                    Relationship.__table__.update().where(\n",
    "                        Relationship.target_entity_id.in_(original_entity_ids)\n",
    "                    ).values(target_entity_id=merged_entity_id)\n",
    "                )\n",
    "\n",
    "                print(f\"Relationships updated for merged entity {merged_entity_id}\")\n",
    "\n",
    "                session.commit()  # Commit the relationship updates\n",
    "                print(f\"Merged entity {cluster_name} processing complete.\")\n",
    "                cluster_df.loc[cluster_df[\"cluster\"] == cluster_name, \"processed\"] = True\n",
    "                cluster_df.to_pickle(\"cluster_entities.pkl\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing cluster {cluster_name}: {e}\", exc_info=True)\n",
    "\n",
    "            print(f\"Error processing cluster {cluster_name}: {e}\")\n",
    "            session.rollback()\n",
    "        finally:\n",
    "            session.close()\n",
    "    else:\n",
    "        print(f\"Merged entity {cluster_name} is invalid or empty.\", merged_entity)\n",
    "\n",
    "    print(\"*\"* 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "SELECT e.id, e.name\n",
    "FROM entities_150001 e\n",
    "WHERE NOT EXISTS (\n",
    "  SELECT 1\n",
    "  FROM relationships_150001 r\n",
    "  WHERE r.source_entity_id = e.id\n",
    "     OR r.target_entity_id = e.id\n",
    ");\n",
    "```\n",
    "\n",
    "```sql\n",
    "START TRANSACTION;\n",
    "\n",
    "DELETE FROM entities_150001\n",
    "WHERE NOT EXISTS (\n",
    "  SELECT 1\n",
    "  FROM relationships_150001 r\n",
    "  WHERE r.source_entity_id = entities_150001.id\n",
    "     OR r.target_entity_id = entities_150001.id\n",
    ");\n",
    "\n",
    "SELECT ROW_COUNT();\n",
    "\n",
    "COMMIT;\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
