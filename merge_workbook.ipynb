{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>entity_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_description</th>\n",
       "      <th>entity_metadata</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8qoRIe0L_iter_1_idx1</td>\n",
       "      <td>30189</td>\n",
       "      <td>ALTER TABLE statement</td>\n",
       "      <td>Used to set a normal table to a cached table i...</td>\n",
       "      <td>{'topic': 'ALTER TABLE statement', 'usage': 'U...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8qoRIe0L_iter_1_idx1</td>\n",
       "      <td>61013</td>\n",
       "      <td>ALTER TABLE statement</td>\n",
       "      <td>The SQL statement used to set a normal table t...</td>\n",
       "      <td>{'SQL': 'ALTER TABLE users CACHE;', 'topic': '...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8qoRIe0L_iter_1_idx2</td>\n",
       "      <td>2226</td>\n",
       "      <td>ALTER TABLE statement</td>\n",
       "      <td>The ALTER TABLE statement is used to modify th...</td>\n",
       "      <td>{'details': {'conversion': 'to/from gbk charac...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8qoRIe0L_iter_1_idx2</td>\n",
       "      <td>32690</td>\n",
       "      <td>ALTER TABLE statement</td>\n",
       "      <td>SQL statement used to modify an existing table...</td>\n",
       "      <td>{'clauses': ['CHARACTER SET', 'COLLATE'], 'pro...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mGjcb4bq_iter_1_idx1</td>\n",
       "      <td>53636</td>\n",
       "      <td>ANALYZE TABLE</td>\n",
       "      <td>The SQL statement used to initiate an analysis...</td>\n",
       "      <td>{'description': 'SQL statement to analyze a ta...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>UzFd440w_iter_1_idx1</td>\n",
       "      <td>54935</td>\n",
       "      <td>version</td>\n",
       "      <td>The version of the component to uninstall.</td>\n",
       "      <td>{'required': False, 'topic': 'version', 'unins...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>quM1H6XE_iter_1_idx1</td>\n",
       "      <td>55832</td>\n",
       "      <td>version</td>\n",
       "      <td>The version number of the DM cluster to be dep...</td>\n",
       "      <td>{'description': 'Version number of the DM clus...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>quM1H6XE_iter_1_idx1</td>\n",
       "      <td>54985</td>\n",
       "      <td>version</td>\n",
       "      <td>The target version for the upgrade. Must be a ...</td>\n",
       "      <td>{'example': 'v8.1.1', 'restrictions': ['Must b...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>quM1H6XE_iter_1_idx1</td>\n",
       "      <td>55642</td>\n",
       "      <td>version</td>\n",
       "      <td>The version number of the TiDB cluster to depl...</td>\n",
       "      <td>{'description': 'the version number of the TiD...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>quM1H6XE_iter_1_idx1</td>\n",
       "      <td>55157</td>\n",
       "      <td>version</td>\n",
       "      <td>The target version to upgrade the TiDB cluster...</td>\n",
       "      <td>{'constraints': ['Must be higher than the curr...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>572 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  cluster  entity_id            entity_name  \\\n",
       "0    8qoRIe0L_iter_1_idx1      30189  ALTER TABLE statement   \n",
       "1    8qoRIe0L_iter_1_idx1      61013  ALTER TABLE statement   \n",
       "2    8qoRIe0L_iter_1_idx2       2226  ALTER TABLE statement   \n",
       "3    8qoRIe0L_iter_1_idx2      32690  ALTER TABLE statement   \n",
       "4    mGjcb4bq_iter_1_idx1      53636          ANALYZE TABLE   \n",
       "..                    ...        ...                    ...   \n",
       "567  UzFd440w_iter_1_idx1      54935                version   \n",
       "568  quM1H6XE_iter_1_idx1      55832                version   \n",
       "569  quM1H6XE_iter_1_idx1      54985                version   \n",
       "570  quM1H6XE_iter_1_idx1      55642                version   \n",
       "571  quM1H6XE_iter_1_idx1      55157                version   \n",
       "\n",
       "                                    entity_description  \\\n",
       "0    Used to set a normal table to a cached table i...   \n",
       "1    The SQL statement used to set a normal table t...   \n",
       "2    The ALTER TABLE statement is used to modify th...   \n",
       "3    SQL statement used to modify an existing table...   \n",
       "4    The SQL statement used to initiate an analysis...   \n",
       "..                                                 ...   \n",
       "567         The version of the component to uninstall.   \n",
       "568  The version number of the DM cluster to be dep...   \n",
       "569  The target version for the upgrade. Must be a ...   \n",
       "570  The version number of the TiDB cluster to depl...   \n",
       "571  The target version to upgrade the TiDB cluster...   \n",
       "\n",
       "                                       entity_metadata  processed  \n",
       "0    {'topic': 'ALTER TABLE statement', 'usage': 'U...      False  \n",
       "1    {'SQL': 'ALTER TABLE users CACHE;', 'topic': '...      False  \n",
       "2    {'details': {'conversion': 'to/from gbk charac...      False  \n",
       "3    {'clauses': ['CHARACTER SET', 'COLLATE'], 'pro...      False  \n",
       "4    {'description': 'SQL statement to analyze a ta...      False  \n",
       "..                                                 ...        ...  \n",
       "567  {'required': False, 'topic': 'version', 'unins...      False  \n",
       "568  {'description': 'Version number of the DM clus...      False  \n",
       "569  {'example': 'v8.1.1', 'restrictions': ['Must b...      False  \n",
       "570  {'description': 'the version number of the TiD...      False  \n",
       "571  {'constraints': ['Must be higher than the curr...      False  \n",
       "\n",
       "[572 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from llm_inference.base import LLMInterface\n",
    "from setting.db import SessionLocal\n",
    "import logging\n",
    "from models.entity import get_entity_model\n",
    "from models.relationship import get_relationship_model\n",
    "\n",
    "\n",
    "Entity = get_entity_model(\"entities_150001\", 1536)\n",
    "Relationship = get_relationship_model(\"relationships_150001\", 1536)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "llm_client = LLMInterface(\"ollama\", \"deepseek-qwen-32b\")\n",
    "cluster_df = pd.read_pickle(\"cluster_entities.pkl\")\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "\n",
    "from typing import Mapping, Any\n",
    "\n",
    "embedding_model = openai.OpenAI()\n",
    "\n",
    "def get_text_embedding(text: str, model=\"text-embedding-3-small\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return embedding_model.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "\n",
    "def get_entity_description_embedding(\n",
    "    name: str, description: str\n",
    "):\n",
    "    combined_text = f\"{name}: {description}\"\n",
    "    return get_text_embedding(combined_text)\n",
    "\n",
    "\n",
    "def get_entity_metadata_embedding(\n",
    "    metadata: dict[Mapping, Any]\n",
    "):\n",
    "    combined_text = json.dumps(metadata)\n",
    "    return get_text_embedding(combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 8qoRIe0L_iter_1_idx1\n",
      " - ID: 61013, Name: ALTER TABLE statement, Description: The SQL statement used to set a normal table to a cached table.\n",
      "   - Metadata: {'SQL': 'ALTER TABLE users CACHE;', 'topic': 'Caching a Table'}\n",
      " - ID: 30189, Name: ALTER TABLE statement, Description: Used to set a normal table to a cached table in TiDB.\n",
      "   - Metadata: {'topic': 'ALTER TABLE statement', 'usage': 'Used with the `CACHE` keyword to convert a normal table to a cached table. Example: `ALTER TABLE users CACHE;`'}\n",
      "134\n"
     ]
    }
   ],
   "source": [
    "from entity_agg import merge_entities, should_merge_entities, group_mergeable_entities\n",
    "\n",
    "cluster_mapping = {}\n",
    "for _, row in cluster_df.iterrows():\n",
    "    if row['processed'] == True:\n",
    "        continue\n",
    "\n",
    "    cluster_name = row['cluster']\n",
    "    entity = Entity(\n",
    "        id=row['entity_id'],\n",
    "        name=row['entity_name'],\n",
    "        description=row['entity_description'],\n",
    "        meta=row['entity_metadata']\n",
    "    )\n",
    "    \n",
    "    if cluster_name not in cluster_mapping:\n",
    "        cluster_mapping[cluster_name] = set()\n",
    "    \n",
    "    cluster_mapping[cluster_name].add(entity)\n",
    "\n",
    "if cluster_mapping:\n",
    "    first_cluster = next(iter(cluster_mapping))\n",
    "    print(f\"Cluster: {first_cluster}\")\n",
    "    for entity in cluster_mapping[first_cluster]:\n",
    "        print(f\" - ID: {entity.id}, Name: {entity.name}, Description: {entity.description}\")\n",
    "        print(f\"   - Metadata: {entity.meta}\")\n",
    "\n",
    "print(len(cluster_mapping))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge entities cluster 8qoRIe0L_iter_1_idx1, count 2\n",
      "prompt token 492\n",
      "skip merge entities cluster 8qoRIe0L_iter_1_idx1, count 2\n",
      "merge entities cluster 8qoRIe0L_iter_1_idx2, count 2\n",
      "prompt token 598\n",
      "skip merge entities cluster 8qoRIe0L_iter_1_idx2, count 2\n",
      "merge entities cluster mGjcb4bq_iter_1_idx1, count 5\n",
      "prompt token 938\n",
      "skip merge entities cluster mGjcb4bq_iter_1_idx1, count 5\n",
      "merge entities cluster mGjcb4bq_iter_1_idx2, count 2\n",
      "prompt token 972\n",
      "skip merge entities cluster mGjcb4bq_iter_1_idx2, count 2\n",
      "merge entities cluster mGjcb4bq_iter_1_idx3, count 2\n",
      "prompt token 511\n",
      "skip merge entities cluster mGjcb4bq_iter_1_idx3, count 2\n",
      "merge entities cluster bX6Fg6jz_iter_1_idx1, count 4\n",
      "prompt token 632\n",
      "skip merge entities cluster bX6Fg6jz_iter_1_idx1, count 4\n",
      "merge entities cluster bX6Fg6jz_iter_1_idx2, count 2\n",
      "prompt token 627\n",
      "skip merge entities cluster bX6Fg6jz_iter_1_idx2, count 2\n",
      "merge entities cluster bX6Fg6jz_iter_1_idx3, count 3\n",
      "prompt token 924\n",
      "skip merge entities cluster bX6Fg6jz_iter_1_idx3, count 3\n",
      "merge entities cluster Lntx2taH_iter_1_idx1, count 18\n",
      "prompt token 5059\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt token\u001b[39m\u001b[38;5;124m\"\u001b[39m, token_count)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m     be_continued \u001b[38;5;241m=\u001b[39m  \u001b[43mshould_merge_entities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m be_continued \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip merge entities cluster \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcluster_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, count \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(entities)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/graph_toolkit/entity_agg.py:398\u001b[0m, in \u001b[0;36mshould_merge_entities\u001b[0;34m(llm_client, cluster_entities, **model_kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou are a knowledge expert assistant specialized in database technologies. You are given a cluster of entities that need to be merged. Each entity contains:\u001b[39m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124m- name: A short string identifier (e.g., \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTiKV\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124m- description: A potentially extensive text describing the entity\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;124m```\u001b[39m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mllm_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m         result \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(extract_json(response))\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/graph_toolkit/llm_inference/base.py:255\u001b[0m, in \u001b[0;36mLLMInterface.generate\u001b[0;34m(self, prompt, context, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate\u001b[39m(\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m, context: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    253\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprovider\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLM generation failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/graph_toolkit/llm_inference/base.py:129\u001b[0m, in \u001b[0;36mOllamaProvider.generate\u001b[0;34m(self, prompt, context, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m full_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;28;01melse\u001b[39;00m prompt\n\u001b[1;32m    128\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: full_prompt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m--> 129\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_with_exponential_backoff\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mollama_base_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/api/generate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/graph_toolkit/llm_inference/base.py:27\u001b[0m, in \u001b[0;36mBaseLLMProvider._retry_with_exponential_backoff\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m attempt \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.12/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.12/site-packages/urllib3/connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.12/http/client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1428\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/graph/lib/python3.12/socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for cluster_name, entities in cluster_mapping.items():\n",
    "    print(f\"merge entities cluster {cluster_name}, count {len(entities)}\")\n",
    "\n",
    "    token_count = merge_entities(llm_client, entities, only_count_token=True)\n",
    "    if token_count > 16384:\n",
    "        print(\"prompt token exceeds 16384\", token_count)\n",
    "        continue\n",
    "\n",
    "    model_args = {}\n",
    "    if token_count > 7000:\n",
    "        model_args[\"options\"]={\n",
    "            \"num_ctx\": token_count+1500,\n",
    "            \"num_gpu\": 80,\n",
    "            \"num_predict\": 8192,\n",
    "            \"temperature\": 0.1,\n",
    "        }\n",
    "    else:\n",
    "        model_args[\"options\"]={\n",
    "            \"num_ctx\": 8092,\n",
    "            \"num_gpu\": 80,\n",
    "            \"num_predict\": 8192,\n",
    "            \"temperature\": 0.1,\n",
    "        }\n",
    "\n",
    "    print(\"prompt token\", token_count)\n",
    "    try:\n",
    "        check_result =  should_merge_entities(llm_client, entities, **model_args)\n",
    "        if check_result.get(\"should_merge\", False) is False:\n",
    "            print(f\"skip merge entities cluster {cluster_name}, count {len(entities)}, reason {check_result}\")\n",
    "            continue\n",
    "        merged_entity = merge_entities(llm_client, entities, **model_args)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing cluster {cluster_name}: {e}\", exc_info=True)\n",
    "        continue\n",
    "\n",
    "    if isinstance(merged_entity,dict) and \"name\" in merged_entity and \"description\" in merged_entity and \"meta\" in merged_entity:\n",
    "        try:\n",
    "            with SessionLocal() as session:\n",
    "                # Step 1: Write the merged entity to the database\n",
    "                new_entity = Entity(\n",
    "                    name=merged_entity[\"name\"],\n",
    "                    description=merged_entity[\"description\"],\n",
    "                    meta=merged_entity.get(\"meta\", {}),\n",
    "                    description_vec=get_entity_description_embedding(merged_entity[\"name\"], merged_entity[\"description\"]),\n",
    "                    meta_vec=get_entity_metadata_embedding(merged_entity.get(\"meta\", {}))\n",
    "                )\n",
    "                print(new_entity.name)\n",
    "                session.add(new_entity)\n",
    "                session.flush()\n",
    "                merged_entity_id = new_entity.id\n",
    "                print(f\"Merged entity created with ID: {merged_entity_id}\")\n",
    "                original_entity_ids = {entity.id for entity in entities}\n",
    "                 # Step 2: Update relationships to reference the merged entity\n",
    "                # Bulk update source entity IDs\n",
    "                session.execute(\n",
    "                    Relationship.__table__.update().where(\n",
    "                        Relationship.source_entity_id.in_(original_entity_ids)\n",
    "                    ).values(source_entity_id=merged_entity_id)\n",
    "                )\n",
    "\n",
    "                # Bulk update target entity IDs\n",
    "                session.execute(\n",
    "                    Relationship.__table__.update().where(\n",
    "                        Relationship.target_entity_id.in_(original_entity_ids)\n",
    "                    ).values(target_entity_id=merged_entity_id)\n",
    "                )\n",
    "\n",
    "                print(f\"Relationships updated for merged entity {merged_entity_id}\")\n",
    "\n",
    "                session.commit()  # Commit the relationship updates\n",
    "                print(f\"Merged entity {cluster_name} processing complete.\")\n",
    "                cluster_df.loc[cluster_df[\"cluster\"] == cluster_name, \"processed\"] = True\n",
    "                cluster_df.to_pickle(\"cluster_entities.pkl\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing cluster {cluster_name}: {e}\", exc_info=True)\n",
    "\n",
    "            print(f\"Error processing cluster {cluster_name}: {e}\")\n",
    "            session.rollback()\n",
    "        finally:\n",
    "            session.close()\n",
    "    else:\n",
    "        print(f\"Merged entity {cluster_name} is invalid or empty.\", merged_entity)\n",
    "\n",
    "    print(\"*\"* 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "SELECT e.id, e.name\n",
    "FROM entities_150001 e\n",
    "WHERE NOT EXISTS (\n",
    "  SELECT 1\n",
    "  FROM relationships_150001 r\n",
    "  WHERE r.source_entity_id = e.id\n",
    "     OR r.target_entity_id = e.id\n",
    ");\n",
    "```\n",
    "\n",
    "```sql\n",
    "START TRANSACTION;\n",
    "\n",
    "DELETE FROM entities_150001\n",
    "WHERE NOT EXISTS (\n",
    "  SELECT 1\n",
    "  FROM relationships_150001 r\n",
    "  WHERE r.source_entity_id = entities_150001.id\n",
    "     OR r.target_entity_id = entities_150001.id\n",
    ");\n",
    "\n",
    "SELECT ROW_COUNT();\n",
    "\n",
    "COMMIT;\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
