{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>entity_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_description</th>\n",
       "      <th>entity_metadata</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98xlivxp_iter_1</td>\n",
       "      <td>1165</td>\n",
       "      <td>admin reload opt_rule_blacklist</td>\n",
       "      <td>A command to reload the optimization rule blac...</td>\n",
       "      <td>{'example': 'admin reload opt_rule_blacklist;'...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98xlivxp_iter_1</td>\n",
       "      <td>36657</td>\n",
       "      <td>admin reload opt_rule_blacklist</td>\n",
       "      <td>An SQL statement to reload the optimization ru...</td>\n",
       "      <td>{'effect': 'Applies changes to the optimizatio...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98xlivxp_iter_1</td>\n",
       "      <td>62549</td>\n",
       "      <td>admin reload opt_rule_blacklist</td>\n",
       "      <td>A command to reload the optimization rule bloc...</td>\n",
       "      <td>{'effect': 'Makes changes to the optimization ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DRaW1EY0_iter_1</td>\n",
       "      <td>1185</td>\n",
       "      <td>Subquery Decorrelation</td>\n",
       "      <td>An optimization technique that transforms a co...</td>\n",
       "      <td>{'disadvantage': 'When the correlation is not ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DRaW1EY0_iter_1</td>\n",
       "      <td>30173</td>\n",
       "      <td>Subquery Decorrelation Optimization</td>\n",
       "      <td>A technique used to rewrite correlated subquer...</td>\n",
       "      <td>{'example': 't1_id != t1.int_col rewritten to ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954</th>\n",
       "      <td>qOvacYVV_iter_1</td>\n",
       "      <td>362932</td>\n",
       "      <td>SELECT statement</td>\n",
       "      <td>The SELECT statement is a SQL command used to ...</td>\n",
       "      <td>{'alias_example': 'SELECT 1 AS `identifier`, 2...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>qOvacYVV_iter_1</td>\n",
       "      <td>362949</td>\n",
       "      <td>SELECT statement</td>\n",
       "      <td>The SELECT statement is a SQL command used to ...</td>\n",
       "      <td>{'clauses': ['ORDER BY', 'HAVING', 'WHERE', 'F...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3956</th>\n",
       "      <td>ROGo7dg2_iter_1</td>\n",
       "      <td>362479</td>\n",
       "      <td>TiKV Node</td>\n",
       "      <td>A TiKV node is a key component in the TiDB arc...</td>\n",
       "      <td>{'affected_by_placement_rules': True, 'data_st...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>ROGo7dg2_iter_1</td>\n",
       "      <td>362535</td>\n",
       "      <td>TiKV nodes</td>\n",
       "      <td>TiKV nodes are the storage units within a TiDB...</td>\n",
       "      <td>{'action': 'Increase the number of nodes', 'de...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>ROGo7dg2_iter_1</td>\n",
       "      <td>362829</td>\n",
       "      <td>TiKV Node</td>\n",
       "      <td>A TiKV Node is a key-value storage component o...</td>\n",
       "      <td>{'data_type': 'OLTP', 'data_volume_based': {'e...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3959 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              cluster  entity_id                          entity_name  \\\n",
       "0     98xlivxp_iter_1       1165      admin reload opt_rule_blacklist   \n",
       "1     98xlivxp_iter_1      36657      admin reload opt_rule_blacklist   \n",
       "2     98xlivxp_iter_1      62549      admin reload opt_rule_blacklist   \n",
       "3     DRaW1EY0_iter_1       1185               Subquery Decorrelation   \n",
       "4     DRaW1EY0_iter_1      30173  Subquery Decorrelation Optimization   \n",
       "...               ...        ...                                  ...   \n",
       "3954  qOvacYVV_iter_1     362932                     SELECT statement   \n",
       "3955  qOvacYVV_iter_1     362949                     SELECT statement   \n",
       "3956  ROGo7dg2_iter_1     362479                            TiKV Node   \n",
       "3957  ROGo7dg2_iter_1     362535                           TiKV nodes   \n",
       "3958  ROGo7dg2_iter_1     362829                            TiKV Node   \n",
       "\n",
       "                                     entity_description  \\\n",
       "0     A command to reload the optimization rule blac...   \n",
       "1     An SQL statement to reload the optimization ru...   \n",
       "2     A command to reload the optimization rule bloc...   \n",
       "3     An optimization technique that transforms a co...   \n",
       "4     A technique used to rewrite correlated subquer...   \n",
       "...                                                 ...   \n",
       "3954  The SELECT statement is a SQL command used to ...   \n",
       "3955  The SELECT statement is a SQL command used to ...   \n",
       "3956  A TiKV node is a key component in the TiDB arc...   \n",
       "3957  TiKV nodes are the storage units within a TiDB...   \n",
       "3958  A TiKV Node is a key-value storage component o...   \n",
       "\n",
       "                                        entity_metadata  processed  \n",
       "0     {'example': 'admin reload opt_rule_blacklist;'...      False  \n",
       "1     {'effect': 'Applies changes to the optimizatio...      False  \n",
       "2     {'effect': 'Makes changes to the optimization ...      False  \n",
       "3     {'disadvantage': 'When the correlation is not ...      False  \n",
       "4     {'example': 't1_id != t1.int_col rewritten to ...      False  \n",
       "...                                                 ...        ...  \n",
       "3954  {'alias_example': 'SELECT 1 AS `identifier`, 2...      False  \n",
       "3955  {'clauses': ['ORDER BY', 'HAVING', 'WHERE', 'F...      False  \n",
       "3956  {'affected_by_placement_rules': True, 'data_st...      False  \n",
       "3957  {'action': 'Increase the number of nodes', 'de...      False  \n",
       "3958  {'data_type': 'OLTP', 'data_volume_based': {'e...      False  \n",
       "\n",
       "[3959 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from llm_inference.base import LLMInterface\n",
    "from setting.db import SessionLocal\n",
    "import logging\n",
    "from models.entity import get_entity_model\n",
    "from models.relationship import get_relationship_model\n",
    "\n",
    "\n",
    "Entity = get_entity_model(\"entities_120001\", 1536)\n",
    "Relationship = get_relationship_model(\"relationships_120001\", 1536)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "llm_client = LLMInterface(\"ollama\", \"deepseek-r1:14b\")\n",
    "cluster_df = pd.read_pickle(\"cluster_entities.pkl\")\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "\n",
    "from typing import Mapping, Any\n",
    "\n",
    "embedding_model = openai.OpenAI()\n",
    "\n",
    "def get_text_embedding(text: str, model=\"text-embedding-3-small\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return embedding_model.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "\n",
    "def get_entity_description_embedding(\n",
    "    name: str, description: str\n",
    "):\n",
    "    combined_text = f\"{name}: {description}\"\n",
    "    return get_text_embedding(combined_text)\n",
    "\n",
    "\n",
    "def get_entity_metadata_embedding(\n",
    "    metadata: dict[Mapping, Any]\n",
    "):\n",
    "    combined_text = json.dumps(metadata)\n",
    "    return get_text_embedding(combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 98xlivxp_iter_1\n",
      " - ID: 36657, Name: admin reload opt_rule_blacklist, Description: An SQL statement to reload the optimization rule blocklist, making changes effective immediately for all connections on the corresponding TiDB server.\n",
      "   - Metadata: {'effect': 'Applies changes to the optimization rule blocklist.', 'immediacy': 'Changes take effect immediately.', 'scope': 'All connections on the TiDB server where the statement is executed.', 'topic': 'Statement Execution'}\n",
      " - ID: 62549, Name: admin reload opt_rule_blacklist, Description: A command to reload the optimization rule blocklist, making changes effective.\n",
      "   - Metadata: {'effect': 'Makes changes to the optimization rule blocklist effective immediately', 'note': 'Run this command on each TiDB server if you want all TiDB servers of the cluster to take effect', 'scope': 'The TiDB server where the command is executed', 'topic': 'Reload Blocklist'}\n",
      " - ID: 1165, Name: admin reload opt_rule_blacklist, Description: A command to reload the optimization rule blacklist. This applies changes made to the mysql.opt_rule_blacklist table and is typically executed after modifying the blacklist (e.g., after inserting or removing rules).\n",
      "   - Metadata: {'example': 'admin reload opt_rule_blacklist;', 'execution': 'Executed after modifying the blacklist (e.g., after inserting or removing rules).', 'purpose': 'reload optimization rule blacklist / Applies changes made to the mysql.opt_rule_blacklist table.', 'topic': 'admin reload opt_rule_blacklist', 'usage': 'admin reload opt_rule_blacklist;'}\n",
      "1109\n"
     ]
    }
   ],
   "source": [
    "from entity_agg import merge_entities, should_merge_entities\n",
    "\n",
    "cluster_mapping = {}\n",
    "for _, row in cluster_df.iterrows():\n",
    "    if row['processed'] == True:\n",
    "        continue\n",
    "\n",
    "    cluster_name = row['cluster']\n",
    "    entity = Entity(\n",
    "        id=row['entity_id'],\n",
    "        name=row['entity_name'],\n",
    "        description=row['entity_description'],\n",
    "        meta=row['entity_metadata']\n",
    "    )\n",
    "    \n",
    "    if cluster_name not in cluster_mapping:\n",
    "        cluster_mapping[cluster_name] = set()\n",
    "    \n",
    "    cluster_mapping[cluster_name].add(entity)\n",
    "\n",
    "if cluster_mapping:\n",
    "    first_cluster = next(iter(cluster_mapping))\n",
    "    print(f\"Cluster: {first_cluster}\")\n",
    "    for entity in cluster_mapping[first_cluster]:\n",
    "        print(f\" - ID: {entity.id}, Name: {entity.name}, Description: {entity.description}\")\n",
    "        print(f\"   - Metadata: {entity.meta}\")\n",
    "\n",
    "print(len(cluster_mapping))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge entities cluster 98xlivxp_iter_1, count 3\n",
      "merge entities cluster DRaW1EY0_iter_1, count 3\n",
      "merge entities cluster YLBfYSAE_iter_1, count 3\n",
      "merge entities cluster 3Amm31b9_iter_1, count 4\n",
      "prompt token 844\n",
      "Subquery Optimization\n",
      "Merged entity created with ID: 450015\n",
      "Merged entity 3Amm31b9_iter_1 processing complete.\n",
      "****************************************************************************************************\n",
      "merge entities cluster c3gXz5UD_iter_1, count 3\n",
      "merge entities cluster j2Pm1Asv_iter_1, count 3\n",
      "merge entities cluster 0tzAg8Jv_iter_1, count 3\n",
      "merge entities cluster 4gedbViJ_iter_1, count 3\n",
      "merge entities cluster W7gppH2K_iter_1, count 3\n",
      "merge entities cluster mnjHeEvH_iter_1, count 3\n",
      "merge entities cluster QWUi5zi4_iter_1, count 6\n",
      "merge entities cluster NPlIc31A_iter_1, count 3\n",
      "merge entities cluster XWSznHbp_iter_1, count 3\n",
      "merge entities cluster qUJvjOvb_iter_1, count 3\n",
      "merge entities cluster 46CYoUzu_iter_1, count 3\n",
      "merge entities cluster rTHxHEFt_iter_1, count 3\n",
      "merge entities cluster 1207ZtDt_iter_1, count 3\n",
      "merge entities cluster j1CLHBCK_iter_1, count 3\n",
      "merge entities cluster chdIiRLR_iter_1, count 3\n",
      "merge entities cluster XvyKWSso_iter_1, count 7\n",
      "merge entities cluster mXz4DIn1_iter_1, count 3\n",
      "merge entities cluster fJMwra31_iter_1, count 4\n",
      "prompt token 1227\n"
     ]
    }
   ],
   "source": [
    "for cluster_name, entities in cluster_mapping.items():\n",
    "    print(f\"merge entities cluster {cluster_name}, count {len(entities)}\")\n",
    "    if len(entities) != 5 and len(entities) != 4:\n",
    "        continue\n",
    "\n",
    "    token_count = merge_entities(llm_client, entities, only_count_token=True)\n",
    "    if token_count > 16384:\n",
    "        print(\"prompt token exceeds 16384\", token_count)\n",
    "        continue\n",
    "\n",
    "    model_args = {}\n",
    "    if token_count > 2000:\n",
    "       model_args[\"options\"]={\"num_ctx\": token_count+256}\n",
    "\n",
    "    print(\"prompt token\", token_count)\n",
    "    try:\n",
    "        be_continued =  should_merge_entities(llm_client, entities, **model_args)\n",
    "        if be_continued is False:\n",
    "            continue\n",
    "        merged_entity = merge_entities(llm_client, entities, **model_args)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing cluster {cluster_name}: {e}\", exc_info=True)\n",
    "        continue\n",
    "\n",
    "    if isinstance(merged_entity,dict) and \"name\" in merged_entity and \"description\" in merged_entity and \"meta\" in merged_entity:\n",
    "        try:\n",
    "            with SessionLocal() as session:\n",
    "                # Step 1: Write the merged entity to the database\n",
    "                new_entity = Entity(\n",
    "                    name=merged_entity[\"name\"],\n",
    "                    description=merged_entity[\"description\"],\n",
    "                    meta=merged_entity.get(\"meta\", {}),\n",
    "                    description_vec=get_entity_description_embedding(merged_entity[\"name\"], merged_entity[\"description\"]),\n",
    "                    meta_vec=get_entity_metadata_embedding(merged_entity.get(\"meta\", {}))\n",
    "                )\n",
    "                print(new_entity.name)\n",
    "                session.add(new_entity)\n",
    "                session.flush()\n",
    "                merged_entity_id = new_entity.id\n",
    "                print(f\"Merged entity created with ID: {merged_entity_id}\")\n",
    "\n",
    "                original_entity_ids = {entity.id for entity in entities}\n",
    "                # Step 2: Update relationships to reference the merged entity\n",
    "                # Find all relationships where the original entities are either source or target\n",
    "                relationships_to_update = session.query(Relationship).filter(\n",
    "                    (Relationship.source_entity_id.in_(original_entity_ids)) |\n",
    "                    (Relationship.target_entity_id.in_(original_entity_ids))\n",
    "                ).all()\n",
    "\n",
    "                for rel in relationships_to_update:\n",
    "                    if rel.source_entity_id in original_entity_ids:\n",
    "                        rel.source_entity_id = merged_entity_id\n",
    "                    if rel.target_entity_id in original_entity_ids:\n",
    "                        rel.target_entity_id = merged_entity_id\n",
    "\n",
    "                session.commit()  # Commit the relationship updates\n",
    "                print(f\"Merged entity {cluster_name} processing complete.\")\n",
    "                cluster_df.loc[cluster_df[\"cluster\"] == cluster_name, \"processed\"] = True\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing cluster {cluster_name}: {e}\", exc_info=True)\n",
    "\n",
    "            print(f\"Error processing cluster {cluster_name}: {e}\")\n",
    "            session.rollback()\n",
    "        finally:\n",
    "            session.close()\n",
    "    else:\n",
    "        print(f\"Merged entity {cluster_name} is invalid or empty.\", merged_entity)\n",
    "\n",
    "    print(\"*\"* 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df.to_pickle(\"cluster_entities.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
